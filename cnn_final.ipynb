{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset and reshape accordingly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785)\n",
      "(28000, 784)\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "print train_data.shape #(42000, 784)\n",
    "print test_data.shape #(28000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_data.drop(['label'], axis = 1)\n",
    "label = train_data.label\n",
    "target = pd.get_dummies(label, columns=['label'], drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31500, 784)\n",
      "(10500, 784)\n"
     ]
    }
   ],
   "source": [
    "x_train,x_cv,y_train,y_cv = train_test_split(train,target,test_size = 0.25, random_state = 4)\n",
    "print x_train.shape #(31500, 784)\n",
    "print x_cv.shape #(10500, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reshape df\n",
    "x_arr = np.array(x_train)\n",
    "x_cv_arr = np.array(x_cv)\n",
    "X = x_arr.reshape(31500,28,28,1)\n",
    "X_cv = x_cv_arr.reshape(10500,28,28,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Weights and Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initializing weights and bias for convolution layer\n",
    "\n",
    "W1 = 0.1*np.random.rand(3,3,3,1)\n",
    "b1 = 0.1*np.random.rand(3,1)\n",
    "\n",
    "## Initializing weights and bias for fully connected layer\n",
    "theta = 0.1*np.random.rand(588,10)\n",
    "bias = 0.1*np.random.rand(1,10)\n",
    "\n",
    "## Normalizing input data\n",
    "x_arr -= int(np.mean(x_arr))\n",
    "x_arr = x_arr.astype(float)\n",
    "x_arr /= int(np.std(x_arr))\n",
    "\n",
    "## Stacking features and labels \n",
    "train_data = np.hstack((x_arr,np.array(y_train)))\n",
    "t = train_data[0:400]\n",
    "\n",
    "## Normalizing cross-validation data\n",
    "x_cv_arr -= int(np.mean(x_cv_arr))\n",
    "x_cv_arr = x_cv_arr.astype(float)\n",
    "x_cv_arr /= int(np.std(x_cv_arr))\n",
    "\n",
    "## Training the model on 400 images, and cv on 100 due to computation issue\n",
    "cv_data = np.hstack((x_cv_arr,np.array(y_cv)))\n",
    "test_data = x_cv_arr[0:100]\n",
    "Y_cv = np.array(y_cv)[0:100]\n",
    "\n",
    "np.random.shuffle(train_data)\n",
    "\n",
    "## Assigning hyperparameter values\n",
    "learning_rate = 0.01\n",
    "batch_size = 40\n",
    "num_epochs = 10\n",
    "num_images = len(t)   ##Number of the input training examples\n",
    "w = 28\n",
    "l = 1\n",
    "l1 = len(W1)    ## no. of filters in W1\n",
    "f = len(W1[0])\n",
    "\n",
    "# print X_cv.shape (10500, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PADDING function\n",
    "def zero_pad(data, pad):\n",
    "    data_pad = np.pad(data,((0,0),(pad,pad),(pad,pad),(0,0)), 'constant')\n",
    "    return data_pad\n",
    "\n",
    "## Function to get the coordinates of maxpool element\n",
    "def idxargmax(a):\n",
    "    idx = np.argmax(a, axis=None)\n",
    "    multi_idx = np.unravel_index(idx, a.shape)\n",
    "    if np.isnan(a[multi_idx]):\n",
    "        nan_count = np.sum(np.isnan(a))\n",
    "        idx = np.argpartition(a, -nan_count-1, axis=None)[-nan_count-1]\n",
    "        idx = np.argsort(a, axis=None)[-nan_count-1]\n",
    "        multi_idx = np.unravel_index(idx, a.shape)\n",
    "    return multi_idx\n",
    "\n",
    "## Maxpool function\n",
    "def max_pool(X,f,stride):\n",
    "    (m, w, w, c) = X.shape\n",
    "    output_size = int((w-f)/stride+1)\n",
    "    pool = np.zeros((m,output_size,output_size, c))\n",
    "    for e in range(0,m):\n",
    "        for k in range(0,c):\n",
    "            for i in range(output_size):\n",
    "                for j in range(output_size):\n",
    "                    pool[e,i,j,k] = np.max(X[e,i*stride:i*stride+f,j*stride:j*stride+f,k])\n",
    "    return pool\n",
    "\n",
    "## Softmax\n",
    "def softmax_cost(out,y):\n",
    "    eout = np.exp(out, dtype=np.float)  \n",
    "    probs = eout/np.sum(eout, axis = 1)[:,None]\n",
    "    \n",
    "    p = np.sum(np.multiply(y,probs), axis = 1)\n",
    "    prob_label = np.argmax(np.array(probs), axis = 1)    # arguments of max values\n",
    "    cost = -np.log(p)    # -log(y*prob)\n",
    "    \n",
    "    return p, cost, probs, prob_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_net(input_data, Y, W1, b1, theta, bias):\n",
    "    \n",
    "## Forward propagation\n",
    "\n",
    "    ## Input shape\n",
    "    m, w, w, c = input_data.shape\n",
    "    \n",
    "    ## no. of filters in layer_1\n",
    "    l1 = len(W1)\n",
    "\n",
    "    ## Shape of the filter used\n",
    "    (f, f, _) = W1[0].shape\n",
    "    pad = 1\n",
    "    ## stride = 1, to make calculations easier\n",
    "    \n",
    "    ## Convolution layer1 output dimensions\n",
    "    nw1 = w+(2*pad)-f + 1\n",
    "\n",
    "    ## Initializing output image matrices after convolutions\n",
    "    conv1 = np.zeros((m,nw1,nw1,l1))\n",
    "\n",
    "    ## Padding the input images\n",
    "    input_pad = zero_pad(input_data,pad)\n",
    "\n",
    "    ## Convolution layer\n",
    "    ## Looping over the no. of examples, no. of filters, height and width (h,w) of image\n",
    "    for i in range(0,m):\n",
    "        for j in range(0,l1):\n",
    "            for k in range(0,nw1): \n",
    "                for l in range(0,nw1):\n",
    "                    conv1[i,k,l,j] = np.sum(input_pad[i,k:k+f,l:l+f]*W1[j])+b1[j]\n",
    "\n",
    "        conv1[i,:,:,:][conv1[i,:,:,:] <= 0] = 0                           ##relu activation\n",
    "\n",
    "    \n",
    "    ## Pooling layer after max_pooling filter size of 2x2 and stride 2\n",
    "    pooled_layer = max_pool(conv1, 2, 2)  \n",
    "    \n",
    "    ## Fully connected layer of neurons\n",
    "    fc1 = pooled_layer.reshape(m,int((nw1/2)*(nw1/2)*l1))\n",
    "\n",
    "    ## Output layer of mx10 activation units\n",
    "    out = np.dot(fc1,theta) + bias\n",
    "        \n",
    "    ## Using softmax to get the cost    \n",
    "    p, cost, probs, prob_label = softmax_cost(out, Y)\n",
    "    \n",
    "    acc = []\n",
    "    for i in range(0,len(Y)):\n",
    "        if prob_label[i]==np.argmax(np.array(Y)[i,:]):\n",
    "            acc.append(1)\n",
    "        else:\n",
    "            acc.append(0)\n",
    "\n",
    "## Backpropagation to calculate gradients \n",
    "    \n",
    "    #Backpropogation across\n",
    "    d_out = probs - Y\n",
    "\n",
    "    #Fully connected layer\n",
    "    dtheta = np.dot(d_out.T, fc1)\n",
    "    dbias = np.mean(d_out, axis = 0).reshape(1,10)    \n",
    "\n",
    "    dfc1 = np.dot(theta,d_out.T)\n",
    "    \n",
    "    #Pooling and Convolution layer\n",
    "    dpool = dfc1.T.reshape((m, int(nw1/2), int(nw1/2), l1))\n",
    "    dconv1 = np.zeros((m, nw1, nw1, l1)) #initialization \n",
    "    \n",
    "    for k in range(0,m):\n",
    "        for c in range(0,l1):\n",
    "            i=0\n",
    "            while(i<nw1):\n",
    "                j=0\n",
    "                while(j<nw1):\n",
    "                    (a,b) = idxargmax(conv1[k,i:i+2,j:j+2,c]) ## Getting indexes of maximum value in the array\n",
    "                    dconv1[k,i+a,j+b,c] = dpool[k,int(i/2),int(j/2),c]\n",
    "                    j+=2\n",
    "                i+=2\n",
    "\n",
    "        dconv1[conv1<=0]=0 #brelu\n",
    "\n",
    "    \n",
    "    dW1_stack = np.zeros((m,l1,f,f,1))\n",
    "    db1_stack = np.zeros((m,l1,1))\n",
    "\n",
    "    dW1 = np.zeros((l1,f,f,1))\n",
    "    db1 = np.zeros((l1,1))\n",
    "\n",
    "    ## looping through the one batch of 40 examples\n",
    "    for i in range(0,m):\n",
    "        for c in range(0,l1):\n",
    "            for x in range(0,nw1):\n",
    "                for y in range(0,nw1):\n",
    "                    dW1_stack[i,:,:,c] += dconv1[i,x,y,c]*input_pad[i,x:x+f,y:y+f,:]\n",
    "            db1_stack[i,c] = np.sum(dconv1[i,:,:,c])\n",
    "        dconv1[conv1<=0]=0\n",
    "        \n",
    "        dW1 = np.mean(dW1_stack, axis = 0)\n",
    "        db1 = np.mean(db1_stack, axis = 0)\n",
    "        \n",
    "    return dW1, db1, dtheta, dbias, cost, probs, prob_label, acc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer(batch,learning_rate,W1,b1,theta,bias):\n",
    "    \n",
    "    ## Slicing train data and labels from batch\n",
    "    X = batch[:,0:-10]\n",
    "    X = X.reshape(len(batch), w, w, l)\n",
    "    Y = batch[:,784:794]\n",
    "    \n",
    "    \n",
    "    batch_size = len(batch)\n",
    "    \n",
    "    ## Initializing gradient matrices \n",
    "    bW1 = {}\n",
    "    dW1 = np.zeros((l1,f,f,1))\n",
    "    db1 = np.zeros((l1,1))\n",
    "    \n",
    "    dtheta = np.zeros(theta.shape)\n",
    "    dbias = np.zeros(bias.shape)\n",
    "    \n",
    "    grads = conv_net(X,Y,W1,b1,theta,bias)\n",
    "    [dW1, db1, dtheta, dbias, cost_, probs_, prob_label, acc_] = grads\n",
    "    \n",
    "    #Updating weights for convolution layer and biases\n",
    "    W1 = W1-learning_rate*(dW1) #convolution\n",
    "    b1 = b1-learning_rate*(db1)\n",
    "    theta = theta-learning_rate*(dtheta.T) #fully connected layer\n",
    "    bias = bias-learning_rate*(dbias)\n",
    "    \n",
    "    batch_cost = np.mean(cost_) # calculating the cost for each batch\n",
    "    batch_accuracy = sum(acc_)/len(acc_) #Reporting the accuracy for each batch\n",
    "    \n",
    "    return W1, b1, theta, bias, batch_cost, acc_, batch_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_init(train_data,W1,b1,theta,bias):\n",
    "    \n",
    "    cost = []\n",
    "    accuracy = []\n",
    "    for epoch in range(0, num_epochs):\n",
    "        batches = [train_data[k:k + batch_size] for k in xrange(0, len(train_data), batch_size)]\n",
    "        x=0\n",
    "        i = 1\n",
    "        for batch in batches:\n",
    "            \n",
    "            output = optimizer(batch,learning_rate,W1,b1,theta,bias)\n",
    "            [W1, b1, theta, bias, batch_cost,acc_,batch_acc] = output\n",
    "                        \n",
    "            cost.append(batch_cost)\n",
    "            accuracy.append(batch_acc)\n",
    "\n",
    "            print 'ep:%d, Batch_no = %f, Cost = %f, Accuracy = %f' %(epoch,i,batch_cost,batch_acc) \n",
    "            i+=1\n",
    "        print '\\nAfter epoch %d, Batch Cost = %f, Batch Accuracy = %f\\n' %(epoch,batch_cost,batch_acc)\n",
    "    return W1,b1,theta,bias,cost,accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep:0, Batch_no = 1.000000, Cost = 2.356544, Accuracy = 0.025000\n",
      "ep:0, Batch_no = 2.000000, Cost = 2.630894, Accuracy = 0.200000\n",
      "ep:0, Batch_no = 3.000000, Cost = 2.267323, Accuracy = 0.225000\n",
      "ep:0, Batch_no = 4.000000, Cost = 2.700278, Accuracy = 0.175000\n",
      "ep:0, Batch_no = 5.000000, Cost = 1.802651, Accuracy = 0.525000\n",
      "ep:0, Batch_no = 6.000000, Cost = 1.733968, Accuracy = 0.475000\n",
      "ep:0, Batch_no = 7.000000, Cost = 1.656707, Accuracy = 0.475000\n",
      "ep:0, Batch_no = 8.000000, Cost = 1.320234, Accuracy = 0.675000\n",
      "ep:0, Batch_no = 9.000000, Cost = 1.395647, Accuracy = 0.500000\n",
      "ep:0, Batch_no = 10.000000, Cost = 1.588089, Accuracy = 0.475000\n",
      "\n",
      "After epoch 0, Batch Cost = 1.588089, Batch Accuracy = 0.475000\n",
      "\n",
      "ep:1, Batch_no = 1.000000, Cost = 0.880869, Accuracy = 0.825000\n",
      "ep:1, Batch_no = 2.000000, Cost = 0.653239, Accuracy = 0.850000\n",
      "ep:1, Batch_no = 3.000000, Cost = 0.643115, Accuracy = 0.875000\n",
      "ep:1, Batch_no = 4.000000, Cost = 0.720093, Accuracy = 0.725000\n",
      "ep:1, Batch_no = 5.000000, Cost = 0.611841, Accuracy = 0.800000\n",
      "ep:1, Batch_no = 6.000000, Cost = 1.097371, Accuracy = 0.575000\n",
      "ep:1, Batch_no = 7.000000, Cost = 2.155000, Accuracy = 0.375000\n",
      "ep:1, Batch_no = 8.000000, Cost = 1.882039, Accuracy = 0.525000\n",
      "ep:1, Batch_no = 9.000000, Cost = 1.475332, Accuracy = 0.550000\n",
      "ep:1, Batch_no = 10.000000, Cost = 0.972746, Accuracy = 0.650000\n",
      "\n",
      "After epoch 1, Batch Cost = 0.972746, Batch Accuracy = 0.650000\n",
      "\n",
      "ep:2, Batch_no = 1.000000, Cost = 0.581836, Accuracy = 0.875000\n",
      "ep:2, Batch_no = 2.000000, Cost = 0.394084, Accuracy = 0.925000\n",
      "ep:2, Batch_no = 3.000000, Cost = 0.537489, Accuracy = 0.850000\n",
      "ep:2, Batch_no = 4.000000, Cost = 0.460595, Accuracy = 0.900000\n",
      "ep:2, Batch_no = 5.000000, Cost = 0.466506, Accuracy = 0.800000\n",
      "ep:2, Batch_no = 6.000000, Cost = 0.736730, Accuracy = 0.750000\n",
      "ep:2, Batch_no = 7.000000, Cost = 0.751541, Accuracy = 0.800000\n",
      "ep:2, Batch_no = 8.000000, Cost = 0.654641, Accuracy = 0.775000\n",
      "ep:2, Batch_no = 9.000000, Cost = 0.635332, Accuracy = 0.775000\n",
      "ep:2, Batch_no = 10.000000, Cost = 1.120781, Accuracy = 0.575000\n",
      "\n",
      "After epoch 2, Batch Cost = 1.120781, Batch Accuracy = 0.575000\n",
      "\n",
      "ep:3, Batch_no = 1.000000, Cost = 2.262147, Accuracy = 0.300000\n",
      "ep:3, Batch_no = 2.000000, Cost = 1.491915, Accuracy = 0.825000\n",
      "ep:3, Batch_no = 3.000000, Cost = 1.352000, Accuracy = 0.725000\n",
      "ep:3, Batch_no = 4.000000, Cost = 1.166162, Accuracy = 0.825000\n",
      "ep:3, Batch_no = 5.000000, Cost = 1.002542, Accuracy = 0.775000\n",
      "ep:3, Batch_no = 6.000000, Cost = 1.219218, Accuracy = 0.700000\n",
      "ep:3, Batch_no = 7.000000, Cost = 0.677299, Accuracy = 0.750000\n",
      "ep:3, Batch_no = 8.000000, Cost = 0.591620, Accuracy = 0.825000\n",
      "ep:3, Batch_no = 9.000000, Cost = 0.429515, Accuracy = 0.925000\n",
      "ep:3, Batch_no = 10.000000, Cost = 0.455841, Accuracy = 0.875000\n",
      "\n",
      "After epoch 3, Batch Cost = 0.455841, Batch Accuracy = 0.875000\n",
      "\n",
      "ep:4, Batch_no = 1.000000, Cost = 0.381195, Accuracy = 0.900000\n",
      "ep:4, Batch_no = 2.000000, Cost = 0.289223, Accuracy = 0.900000\n",
      "ep:4, Batch_no = 3.000000, Cost = 0.455956, Accuracy = 0.900000\n",
      "ep:4, Batch_no = 4.000000, Cost = 0.312867, Accuracy = 0.925000\n",
      "ep:4, Batch_no = 5.000000, Cost = 0.475023, Accuracy = 0.775000\n",
      "ep:4, Batch_no = 6.000000, Cost = 0.573779, Accuracy = 0.800000\n",
      "ep:4, Batch_no = 7.000000, Cost = 0.559543, Accuracy = 0.825000\n",
      "ep:4, Batch_no = 8.000000, Cost = 0.458549, Accuracy = 0.850000\n",
      "ep:4, Batch_no = 9.000000, Cost = 0.325734, Accuracy = 0.875000\n",
      "ep:4, Batch_no = 10.000000, Cost = 0.516116, Accuracy = 0.850000\n",
      "\n",
      "After epoch 4, Batch Cost = 0.516116, Batch Accuracy = 0.850000\n",
      "\n",
      "ep:5, Batch_no = 1.000000, Cost = 0.482817, Accuracy = 0.775000\n",
      "ep:5, Batch_no = 2.000000, Cost = 0.293761, Accuracy = 0.925000\n",
      "ep:5, Batch_no = 3.000000, Cost = 0.407771, Accuracy = 0.875000\n",
      "ep:5, Batch_no = 4.000000, Cost = 0.268471, Accuracy = 0.950000\n",
      "ep:5, Batch_no = 5.000000, Cost = 0.440796, Accuracy = 0.775000\n",
      "ep:5, Batch_no = 6.000000, Cost = 0.511055, Accuracy = 0.825000\n",
      "ep:5, Batch_no = 7.000000, Cost = 0.538656, Accuracy = 0.850000\n",
      "ep:5, Batch_no = 8.000000, Cost = 0.415674, Accuracy = 0.875000\n",
      "ep:5, Batch_no = 9.000000, Cost = 0.295417, Accuracy = 0.900000\n",
      "ep:5, Batch_no = 10.000000, Cost = 0.542879, Accuracy = 0.825000\n",
      "\n",
      "After epoch 5, Batch Cost = 0.542879, Batch Accuracy = 0.825000\n",
      "\n",
      "ep:6, Batch_no = 1.000000, Cost = 0.548720, Accuracy = 0.675000\n",
      "ep:6, Batch_no = 2.000000, Cost = 0.363553, Accuracy = 0.925000\n",
      "ep:6, Batch_no = 3.000000, Cost = 0.417740, Accuracy = 0.875000\n",
      "ep:6, Batch_no = 4.000000, Cost = 0.234388, Accuracy = 0.950000\n",
      "ep:6, Batch_no = 5.000000, Cost = 0.420504, Accuracy = 0.800000\n",
      "ep:6, Batch_no = 6.000000, Cost = 0.423934, Accuracy = 0.850000\n",
      "ep:6, Batch_no = 7.000000, Cost = 0.489379, Accuracy = 0.825000\n",
      "ep:6, Batch_no = 8.000000, Cost = 0.376213, Accuracy = 0.875000\n",
      "ep:6, Batch_no = 9.000000, Cost = 0.243945, Accuracy = 0.925000\n",
      "ep:6, Batch_no = 10.000000, Cost = 0.484311, Accuracy = 0.850000\n",
      "\n",
      "After epoch 6, Batch Cost = 0.484311, Batch Accuracy = 0.850000\n",
      "\n",
      "ep:7, Batch_no = 1.000000, Cost = 0.379002, Accuracy = 0.875000\n",
      "ep:7, Batch_no = 2.000000, Cost = 0.172843, Accuracy = 0.925000\n",
      "ep:7, Batch_no = 3.000000, Cost = 0.458381, Accuracy = 0.875000\n",
      "ep:7, Batch_no = 4.000000, Cost = 0.194399, Accuracy = 0.950000\n",
      "ep:7, Batch_no = 5.000000, Cost = 0.382868, Accuracy = 0.825000\n",
      "ep:7, Batch_no = 6.000000, Cost = 0.382495, Accuracy = 0.850000\n",
      "ep:7, Batch_no = 7.000000, Cost = 0.453518, Accuracy = 0.825000\n",
      "ep:7, Batch_no = 8.000000, Cost = 0.340325, Accuracy = 0.875000\n",
      "ep:7, Batch_no = 9.000000, Cost = 0.177900, Accuracy = 0.950000\n",
      "ep:7, Batch_no = 10.000000, Cost = 0.378939, Accuracy = 0.900000\n",
      "\n",
      "After epoch 7, Batch Cost = 0.378939, Batch Accuracy = 0.900000\n",
      "\n",
      "ep:8, Batch_no = 1.000000, Cost = 0.289806, Accuracy = 0.900000\n",
      "ep:8, Batch_no = 2.000000, Cost = 0.174535, Accuracy = 0.925000\n",
      "ep:8, Batch_no = 3.000000, Cost = 0.435817, Accuracy = 0.925000\n",
      "ep:8, Batch_no = 4.000000, Cost = 0.171135, Accuracy = 0.950000\n",
      "ep:8, Batch_no = 5.000000, Cost = 0.356769, Accuracy = 0.850000\n",
      "ep:8, Batch_no = 6.000000, Cost = 0.360777, Accuracy = 0.850000\n",
      "ep:8, Batch_no = 7.000000, Cost = 0.441768, Accuracy = 0.850000\n",
      "ep:8, Batch_no = 8.000000, Cost = 0.315792, Accuracy = 0.900000\n",
      "ep:8, Batch_no = 9.000000, Cost = 0.148595, Accuracy = 0.950000\n",
      "ep:8, Batch_no = 10.000000, Cost = 0.325300, Accuracy = 0.900000\n",
      "\n",
      "After epoch 8, Batch Cost = 0.325300, Batch Accuracy = 0.900000\n",
      "\n",
      "ep:9, Batch_no = 1.000000, Cost = 0.271705, Accuracy = 0.900000\n",
      "ep:9, Batch_no = 2.000000, Cost = 0.123898, Accuracy = 0.950000\n",
      "ep:9, Batch_no = 3.000000, Cost = 0.371333, Accuracy = 0.925000\n",
      "ep:9, Batch_no = 4.000000, Cost = 0.162012, Accuracy = 0.975000\n",
      "ep:9, Batch_no = 5.000000, Cost = 0.339014, Accuracy = 0.850000\n",
      "ep:9, Batch_no = 6.000000, Cost = 0.326002, Accuracy = 0.875000\n",
      "ep:9, Batch_no = 7.000000, Cost = 0.411287, Accuracy = 0.850000\n",
      "ep:9, Batch_no = 8.000000, Cost = 0.274722, Accuracy = 0.900000\n",
      "ep:9, Batch_no = 9.000000, Cost = 0.138983, Accuracy = 0.975000\n",
      "ep:9, Batch_no = 10.000000, Cost = 0.354240, Accuracy = 0.875000\n",
      "\n",
      "After epoch 9, Batch Cost = 0.354240, Batch Accuracy = 0.875000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "W1_t,b1_t,theta_t,bias_t,cost_t,accuracy_t = main_init(t,W1,b1,theta,bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
